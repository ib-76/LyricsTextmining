{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 4.2: Title vs. Lyrics Relationship\n",
    "\n",
    "**Cosine over TF-IDF vectors**<br>\n",
    "I created a function where, when a song is passed, the function transforms its title into TF-IDF space.<br>It also transforms all lyrics in the dataset into TF-IDF vectors, then calculates cosine similarity between the title and each lyrics vector.<br> The output prints the top songs with lyrics most similar to the title, as well as the 5 least similar. A CSV file is also saved for further analysis.\n"
   ],
   "id": "5d3b68e280c15c27"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import os\n",
    "\n",
    "# --- 1. Connect to SQL Server ---\n",
    "conn_str = \"mssql+pyodbc://IVAN_PC\\\\SQLEXPRESS/TextMiningHA?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "engine = create_engine(conn_str)\n",
    "\n",
    "# --- 2. Pull song SimilarityData including genre ---\n",
    "df = pd.read_sql(\"\"\"\n",
    "    SELECT song_id, name, lyrics, genre\n",
    "    FROM songs\n",
    "    WHERE lyrics IS NOT NULL\n",
    "\"\"\", engine)\n",
    "\n",
    "# --- 3. TF-IDF Vectorizer for lyrics ---\n",
    "vectorizer_lyrics = TfidfVectorizer(\n",
    "    max_features=10000,\n",
    "    ngram_range=(1, 2),\n",
    "    lowercase=True,\n",
    "    strip_accents=\"unicode\"\n",
    ")\n",
    "X_lyrics = vectorizer_lyrics.fit_transform(df['lyrics'])\n",
    "\n",
    "# --- 4. Function to analyze title vs lyrics ---\n",
    "def title_lyrics_cosine(song_id, top_n=5):\n",
    "    \"\"\"\n",
    "    Computes cosine similarity between a song's title and all lyrics,\n",
    "    prints top N most similar and N least similar lyrics with genre,\n",
    "    and optionally saves results to a CSV.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        idx = df.index[df['song_id'] == song_id][0]\n",
    "    except IndexError:\n",
    "        print(f\"Song ID {song_id} not found.\")\n",
    "        return\n",
    "\n",
    "    # Transform the title using the lyrics vectorizer\n",
    "    title_text = df.iloc[idx]['name']\n",
    "    title_vec = vectorizer_lyrics.transform([title_text])\n",
    "\n",
    "    # Cosine similarity between the title and all lyrics\n",
    "    sims = cosine_similarity(title_vec, X_lyrics).flatten()\n",
    "\n",
    "    # Exclude the song itself\n",
    "    sims_masked = np.copy(sims)\n",
    "    sims_masked[idx] = np.nan\n",
    "\n",
    "    # Top N most similar lyrics\n",
    "    top_idx = np.argsort(-sims_masked)[:top_n]\n",
    "\n",
    "    # Top N least similar lyrics\n",
    "    bottom_idx = np.argsort(sims_masked)[:top_n]\n",
    "\n",
    "    # --- Prepare results for printing ---\n",
    "    def clean_lyrics(text):\n",
    "        return re.sub(r'\\s+', ' ', str(text)).strip()  # remove newlines and extra spaces\n",
    "\n",
    "    top_results = []\n",
    "    bottom_results = []\n",
    "\n",
    "    print(f\"\\n=== Top {top_n} lyrics most similar to title: {title_text} (ID={song_id}) ===\")\n",
    "    for rank, i in enumerate(top_idx, start=1):\n",
    "        snippet = clean_lyrics(df.iloc[i]['lyrics'])\n",
    "        print(f\"{rank}. [{df.iloc[i]['song_id']}] {df.iloc[i]['name']} \"\n",
    "              f\"(Genre: {df.iloc[i]['genre']}, similarity={sims[i]:.3f})\\n   Lyrics: {snippet}\\n\")\n",
    "        top_results.append({\n",
    "            'song_id': df.iloc[i]['song_id'],\n",
    "            'name': df.iloc[i]['name'],\n",
    "            'genre': df.iloc[i]['genre'],\n",
    "            'similarity': sims[i],\n",
    "            'lyrics': snippet\n",
    "        })\n",
    "\n",
    "    print(f\"\\n=== Top {top_n} lyrics least similar to title: {title_text} (ID={song_id}) ===\")\n",
    "    for rank, i in enumerate(bottom_idx, start=1):\n",
    "        snippet = clean_lyrics(df.iloc[i]['lyrics'])\n",
    "        print(f\"{rank}. [{df.iloc[i]['song_id']}] {df.iloc[i]['name']} \"\n",
    "              f\"(Genre: {df.iloc[i]['genre']}, similarity={sims[i]:.3f})\\n   Lyrics: {snippet}\\n\")\n",
    "        bottom_results.append({\n",
    "            'song_id': df.iloc[i]['song_id'],\n",
    "            'name': df.iloc[i]['name'],\n",
    "            'genre': df.iloc[i]['genre'],\n",
    "            'similarity': sims[i],\n",
    "            'lyrics': snippet\n",
    "        })\n",
    "\n",
    "   #  save to CSV\n",
    "\n",
    "        out_dir = \"SimilarityData\"\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        out_path = os.path.join(out_dir,\"cosine_title_similarity.csv\")\n",
    "        all_results = top_results + bottom_results\n",
    "        pd.DataFrame(all_results).to_csv(out_path, index=False)\n",
    "\n",
    "\n",
    "# --- call function ---\n",
    "title_lyrics_cosine('13741824864810098075', top_n=5)\n"
   ],
   "id": "93f9e3bdfc56025a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Jaccard on Clean Tokens**\n",
    "\n",
    "I created a function where, when a song is passed, the function transforms its title into a token set.<br>\n",
    "It also converts all lyrics in the dataset into token sets and calculates Jaccard similarity between the title and each lyrics token set.<br\n",
    "The output prints the top songs with lyrics most similar to the title, as well as the 5 least similar. A CSV file is also saved for further analysis."
   ],
   "id": "4a9df0795a3f1df5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "\n",
    "# --- Connect to SQL Server ---\n",
    "conn_str = \"mssql+pyodbc://IVAN_PC\\\\SQLEXPRESS/TextMiningHA?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "engine = create_engine(conn_str)\n",
    "\n",
    "# --- Pull song data ---\n",
    "df = pd.read_sql(\"\"\"\n",
    "    SELECT song_id, name, genre, cleanTokens\n",
    "    FROM songs\n",
    "    WHERE cleanTokens IS NOT NULL\n",
    "\"\"\", engine)\n",
    "\n",
    "# --- Convert tokens to sets ---\n",
    "def tokens_to_set(tokens_str):\n",
    "    return set(str(tokens_str).split())\n",
    "\n",
    "df['token_set'] = df['cleanTokens'].apply(tokens_to_set)\n",
    "\n",
    "# --- Jaccard similarity function ---\n",
    "def title_lyrics_jaccard(song_id, top_n=5):\n",
    "    try:\n",
    "        idx = df.index[df['song_id'] == song_id][0]\n",
    "    except IndexError:\n",
    "        print(f\"Song ID {song_id} not found.\")\n",
    "        return\n",
    "\n",
    "    title_tokens = tokens_to_set(df.iloc[idx]['name'])\n",
    "\n",
    "    def jaccard(set1, set2):\n",
    "        if not set1 or not set2:\n",
    "            return 0.0\n",
    "        return len(set1 & set2) / len(set1 | set2)\n",
    "\n",
    "    sims = df['token_set'].apply(lambda x: jaccard(title_tokens, x))\n",
    "\n",
    "    # Exclude the song itself\n",
    "    sims[idx] = -1\n",
    "\n",
    "    # Sort by similarity\n",
    "    top_idx = sims.sort_values(ascending=False).head(top_n).index\n",
    "    bottom_idx = sims.sort_values(ascending=True).head(top_n).index\n",
    "\n",
    "    # --- Print top results ---\n",
    "    print(f\"\\n=== Top {top_n} lyrics most similar to title: {df.iloc[idx]['name']} (ID={song_id}) ===\")\n",
    "    top_results = []\n",
    "    for rank, i in enumerate(top_idx, start=1):\n",
    "        snippet = \" \".join(df.iloc[i]['token_set'])\n",
    "        print(f\"{rank}. [{df.iloc[i]['song_id']}] {df.iloc[i]['name']} \"\n",
    "              f\"(Genre: {df.iloc[i]['genre']}, Jaccard={sims[i]:.3f})\\n   Tokens: {snippet}\\n\")\n",
    "        top_results.append({\n",
    "            'song_id': df.iloc[i]['song_id'],\n",
    "            'name': df.iloc[i]['name'],\n",
    "            'genre': df.iloc[i]['genre'],\n",
    "            'jaccard_similarity': sims[i],\n",
    "            'tokens': snippet\n",
    "        })\n",
    "\n",
    "    # --- Print bottom results ---\n",
    "    print(f\"\\n=== Top {top_n} lyrics least similar to title: {df.iloc[idx]['name']} (ID={song_id}) ===\")\n",
    "    bottom_results = []\n",
    "    for rank, i in enumerate(bottom_idx, start=1):\n",
    "        snippet = \" \".join(df.iloc[i]['token_set'])\n",
    "        print(f\"{rank}. [{df.iloc[i]['song_id']}] {df.iloc[i]['name']} \"\n",
    "              f\"(Genre: {df.iloc[i]['genre']}, Jaccard={sims[i]:.3f})\\n   Tokens: {snippet}\\n\")\n",
    "        bottom_results.append({\n",
    "            'song_id': df.iloc[i]['song_id'],\n",
    "            'name': df.iloc[i]['name'],\n",
    "            'genre': df.iloc[i]['genre'],\n",
    "            'jaccard_similarity': sims[i],\n",
    "            'tokens': snippet\n",
    "        })\n",
    "\n",
    "    # --- Save CSV ---\n",
    "\n",
    "        out_dir = \"SimilarityData\"\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        out_path = os.path.join(out_dir,\"jaccard_title_similarity.csv\")\n",
    "        all_results = top_results + bottom_results\n",
    "        pd.DataFrame(all_results).to_csv(out_path, index=False)\n",
    "\n",
    "\n",
    "# --- call function ---\n",
    "title_lyrics_jaccard('13860806082654952241', top_n=5)\n"
   ],
   "id": "f0b72c30f5ce82c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Final Thoughts:\n",
    "\n",
    "Evidently, although Jaccard is faster in performance, its output return is much less comparable to TF-IDF + cosine similarity.<br> This is because titles consist of very few words, while lyrics contain many more words, making the overlap too small to generate meaningful scores. <br>In contrast, TF-IDF + cosine similarity can pick up patterns through repeated words, and TF-IDF assigns higher weights to rare or important words, <br>making it more sensitive to meaningful overlap between a title and lyrics."
   ],
   "id": "e1ab9f4052ea2a9f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
