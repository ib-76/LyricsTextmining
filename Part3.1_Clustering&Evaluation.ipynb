{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Part 3: Modeling & Inference**<br>\n",
    "**Task 3.1.1:  Design a Taxonomy**<br>\n",
    "This code was designed to process all songs' genre, including songs with multiple genres, and map each song to one of a predefined set of six main genres. The cleanGenre column of songs D would then contain only one of these six categories, depending on where the original genre(s) fell in the mapping.\n",
    "\n",
    "However, this approach was ultimately abandoned. After testing with all three clustering methods, it became clear that the dominant genre was overwhelmingly Rock, which made meaningful analysis difficult."
   ],
   "id": "25fb257127d9fe38"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "#  ====== Create SQLAlchemy engine ======\n",
    "# engine = create_engine(\n",
    "#     \"mssql+pyodbc://IVAN_PC\\\\SQLEXPRESS/TextMiningHA?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "# )\n",
    "#\n",
    "# # ====== Pull distinct genres from DB ======\n",
    "# df = pd.read_sql(\"SELECT DISTINCT genre, song_id FROM songs\", engine)\n",
    "#\n",
    "# # ====== Extract unique subgenres ======\n",
    "# subgenres = set()\n",
    "# for row in df['genre'].dropna():\n",
    "#     for tag in row.split(','):\n",
    "#         subgenres.add(tag.strip().lower())\n",
    "#\n",
    "# # ====== Define main genre groups ======\n",
    "# genre_groups = {\n",
    "#     \"Rock\": [],\n",
    "#     \"Metal\": [],\n",
    "#     \"Pop\": [],\n",
    "#     \"Hip-Hop\": [],\n",
    "#     \"Jazz\": [],\n",
    "#     \"Country\": [],\n",
    "#     \"World\": [],\n",
    "# }\n",
    "#\n",
    "# # ====== Assign subgenres to main groups ======\n",
    "# for genre in subgenres:\n",
    "#     g = genre.lower()\n",
    "#     if g in ['alt-rock', 'alternative', 'garage', 'grunge', 'hard-rock', 'indie', 'indie-pop',\n",
    "#              'punk', 'punk-rock', 'psych-rock', 'rock', 'rock-n-roll', 'rockabilly']:\n",
    "#         genre_groups[\"Rock\"].append(g)\n",
    "#     elif g in ['black-metal', 'death-metal', 'metal', 'guitar','metalcore', 'hardcore', 'industrial','goth']:\n",
    "#         genre_groups[\"Metal\"].append(g)\n",
    "#     elif g in ['pop', 'power-pop', 'dance', 'disco', 'house', 'progressive-house','mandopop',\n",
    "#                'j-pop', 'j-rock', 'j-dance', 'synth-pop', 'electro', 'electronic', 'edm','hip-hop', 'r-n-b', 'trip-hop', 'groove', 'funk']:\n",
    "#         genre_groups[\"Pop\"].append(g)\n",
    "#     elif g in ['jazz', 'classical', 'opera', 'piano', 'new-age', 'show-tunes','soul']:\n",
    "#         genre_groups[\"Jazz\"].append(g)\n",
    "#     elif g in ['acoustic', 'folk', 'singer-songwriter', 'songwriter', 'country', 'bluegrass', 'honky-tonk']:\n",
    "#         genre_groups[\"Country\"].append(g)\n",
    "#     else:\n",
    "#         genre_groups[\"World\"].append(g)\n",
    "#\n",
    "# # ====== Flatten mapping for lookup ======\n",
    "# mapping_dict = {kw: main for main, keywords in genre_groups.items() for kw in keywords}\n",
    "#\n",
    "# # ====== Map and update genres in DB ======\n",
    "# from sqlalchemy import text\n",
    "#\n",
    "#\n",
    "# # ====== Map and update genres with majority match ======\n",
    "# with engine.begin() as conn:\n",
    "#     df_all = pd.read_sql(\"SELECT song_id, genre FROM songs WHERE genre IS NOT NULL\", conn)\n",
    "#\n",
    "#     for _, row in df_all.iterrows():\n",
    "#         song_id = row['song_id']\n",
    "#         genres = [g.strip().lower() for g in row['genre'].split(',')]\n",
    "#         unique_genres = list(dict.fromkeys(genres))\n",
    "#\n",
    "#         # Count matches per main genre\n",
    "#         match_counts = {}\n",
    "#         for main_genre, keywords in genre_groups.items():\n",
    "#             count = sum(1 for g in unique_genres if g in keywords)\n",
    "#             if count > 0:\n",
    "#                 match_counts[main_genre] = count\n",
    "#\n",
    "#         # Pick the main genre with the highest matches\n",
    "#         if match_counts:\n",
    "#             chosen_value = max(match_counts, key=match_counts.get)\n",
    "#         else:\n",
    "#             chosen_value = None\n",
    "#\n",
    "#         # Update DB\n",
    "#         stmt = text(\"UPDATE songs SET cleanGenre = :cleanGenre WHERE song_id = :song_id\")\n",
    "#         conn.execute(stmt, {\"cleanGenre\": chosen_value, \"song_id\": song_id})\n",
    "#\n",
    "# print(\"Genre cleaning completed: cleanGenre populated using majority-match rule.\")"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Initially, this code was designed to clean each genre by simply removing duplicates, leaving a single genre per song. However, when encountering songs with multiple genres, I decided to pick the rarest genre in the dataset.\n",
    "\n",
    "This approach was intended to make the data more interesting and to improve the potential for clustering and meaningful analysis, by highlighting less common genres rather than defaulting to the dominant ones."
   ],
   "id": "7692159dded2b2e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# ====== Create SQLAlchemy engine ======\n",
    "engine = create_engine(\n",
    "    \"mssql+pyodbc://IVAN_PC\\\\SQLEXPRESS/TextMiningHA?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    ")\n",
    "\n",
    "# ====== Pull song_id and genre ======\n",
    "df = pd.read_sql(\"SELECT song_id, genre FROM songs\", engine)\n",
    "\n",
    "# ====== Count frequency of all genres ======\n",
    "all_genres = []\n",
    "for g in df['genre']:\n",
    "    all_genres.extend([x.strip().lower() for x in g.split(',')])\n",
    "freq = Counter(all_genres)\n",
    "\n",
    "# ====== Determine cleanGenre safely ======\n",
    "def choose_genre(g):\n",
    "    genres = [x.strip().lower() for x in g.split(',')]\n",
    "    if len(genres) == 1:\n",
    "        return genres[0]  # single genre\n",
    "    # multiple genres: pick the rarest by frequency\n",
    "    rarest = min(genres, key=lambda x: freq.get(x, float('inf')))\n",
    "    return rarest\n",
    "\n",
    "df['cleanGenre'] = df['genre'].apply(choose_genre)\n",
    "\n",
    "# ====== Update the database ======\n",
    "with engine.begin() as conn:\n",
    "    stmt = text(\"UPDATE songs SET cleanGenre = :cleanGenre WHERE song_id = :song_id\")\n",
    "    for _, row in df.iterrows():\n",
    "        conn.execute(stmt, {\"cleanGenre\": row['cleanGenre'], \"song_id\": row['song_id']})\n",
    "\n",
    "print(\"Genre cleaning completed: cleanGenre populated using rarest-genre rule.\")\n"
   ],
   "id": "3c90b5336917d2dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Part 3: Modeling & Inference**<br>\n",
    "In the following cell transforms the cleaned lyrics tokens onto sparse TF-IDF matrix (weighted word importance, including unigrams + bigrams), reduces them dimensionally  with LSA, and prints both the word space and reduced semantic representation for further clustering/analysis."
   ],
   "id": "c07808e3a2a61556"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import pandas as pd\n",
    "import ast\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "conn_str = \"mssql+pyodbc://IVAN_PC\\\\SQLEXPRESS/TextMiningHA?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "\n",
    "\n",
    "# Pull SimilarityData\n",
    "df = pd.read_sql(f\"\"\"\n",
    "    SELECT song_id, name, cleanTokens, genre,cleanGenre\n",
    "    FROM  songs\n",
    "    WHERE cleanTokens IS NOT NULL\n",
    "\"\"\", engine)\n",
    "\n",
    "# --- Convert token strings to lists and join into a single string ---\n",
    "df['clean_text'] = df['cleanTokens'].apply(ast.literal_eval)  # convert string to list\n",
    "df['clean_text'] = df['clean_text'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "# TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=10000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=30,\n",
    "    max_df=0.9,\n",
    "    lowercase=True,\n",
    "    strip_accents=\"unicode\",\n",
    "    token_pattern=r\"\\b\\w+\\b\"\n",
    ")\n",
    "X_sparse = vectorizer.fit_transform(df['clean_text'])\n",
    "\n",
    "# --- TruncatedSVD for LSA ---\n",
    "n_components = 5\n",
    "random_state = 100\n",
    "svd = TruncatedSVD(n_components=n_components, random_state=random_state)\n",
    "X_tfidf = svd.fit_transform(X_sparse)\n",
    "\n",
    "\n",
    "# Optional: DataFrame for inspection\n",
    "tfidf_df = pd.DataFrame(\n",
    "    X_tfidf,\n",
    "    columns=[f'LSA_{i+1}' for i in range(X_tfidf.shape[1])],\n",
    "    index=df['name']\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---- Bag Of Words in format {'...','...',...} ----\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "bow_string = \"{ \" + \", \".join([f\"'{w}'\" for w in vocab]) + \" }\"\n",
    "print(bow_string, len(bow_string))\n",
    "\n",
    "print(tfidf_df.head())\n",
    "\n",
    "# ---- count and list the entire wordspace ----\n",
    "total_words = len(vectorizer.get_feature_names_out())\n",
    "print(\"Total unique words (features):\", total_words)\n",
    "print(sorted(vectorizer.get_feature_names_out()))   # <— uncomment to show all words\n",
    "\n",
    "# ---- choose songs to print horizontally ----\n",
    "rows_selected = tfidf_df.iloc[6:8]\n",
    "# for song_name, row in rows_selected.iterrows():\n",
    "#     words_scores = [f\"{word}:{score:.4f}\" for word, score in row.items()]\n",
    "#     print(f\"{song_name} -> {' | '.join(words_scores)}\\n\")\n"
   ],
   "id": "f972257fbccdb60c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Scree Plot - Elbow Method**<br>This code helps to select the best number of clusters for KMeans by plotting the inertia curve and finding the elbow point automatically.",
   "id": "88b7f4a683b41127"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Suppose X is your feature matrix\n",
    "inertia = []\n",
    "K = range(1,15)\n",
    "\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X_tfidf)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(K, inertia, 'bo-')\n",
    "plt.xlabel('Number of clusters k')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "from kneed import KneeLocator\n",
    "\n",
    "knee = KneeLocator(K, inertia, curve='convex', direction='decreasing')\n",
    "print(\"Elbow at k =\", knee.knee)"
   ],
   "id": "7dad32c493391687",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Task 3.1.2. Apply Multiple Clustering Techniques** K-means method",
   "id": "402b893f51d53c41"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "# ====== Parameters ======\n",
    "k = 5 # number of clusters\n",
    "random_state = 42\n",
    "\n",
    "# ====== K-Means Clustering ======\n",
    "kmeans = KMeans(n_clusters=k, random_state=random_state, n_init=42)\n",
    "kmeans.fit(X_tfidf)\n",
    "\n",
    "# ====== Store cluster labels in DataFrame ======\n",
    "df['kmeans_label'] = kmeans.labels_\n",
    "\n",
    "# ====== PCA for Visualization ======\n",
    "pca = PCA(n_components=2, random_state=random_state)\n",
    "X_pca = pca.fit_transform(X_tfidf)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1],\n",
    "                      c=df['kmeans_label'], cmap='tab10', alpha=0.8, s=40)\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.title('K-Means Clusters in 2D PCA space')\n",
    "plt.legend(*scatter.legend_elements(), title=\"Clusters\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ====== Display all rows and columns (no truncation) ======\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "# ====== Subgenre Summary and Export (without splitting cleanGenre) ======\n",
    "for cluster_id in sorted(df['kmeans_label'].unique()):\n",
    "    cluster_songs = df[df['kmeans_label'] == cluster_id]\n",
    "    total_songs = len(cluster_songs)\n",
    "\n",
    "    # Count exact cleanGenre strings (no splitting)\n",
    "    genre_counts = cluster_songs['cleanGenre'].value_counts()\n",
    "    top5_genres = genre_counts.head(5)\n",
    "    top5_summary = \", \".join([f\"{g} ({c}/{total_songs})\" for g, c in top5_genres.items()])\n",
    "\n",
    "    print(f\"\\n=== Cluster {cluster_id} ({total_songs} songs) | Top genres: {top5_summary} ===\")\n",
    "\n",
    "    # Save cluster songs to CSV\n",
    "    output_folder = r\"MyFiles\"\n",
    "    filename = os.path.join(output_folder, f\"soft_cluster_{cluster_id}.csv\")\n",
    "    cluster_songs[['name', 'genre', 'cleanGenre', 'kmeans_label']].to_csv(filename, index=False)\n"
   ],
   "id": "3e127424663b6baa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Task 3.1.3. Visualise and Evaluate** K-means method",
   "id": "c1865dca7b232d0c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Top 15 genres and cluster IDs\n",
    "top_genres = df['genre'].value_counts().head(15).index.tolist()\n",
    "cluster_ids = sorted(df['kmeans_label'].unique())\n",
    "\n",
    "# ===== Manually assign cluster labels =====\n",
    "manual_labels = {\n",
    "    0: \"Death-Metal\",\n",
    "    1: \"honky-Tonk\",\n",
    "    2: \"grunge\",\n",
    "    3: \"psych-rock\",\n",
    "    4: \"power-pop\",\n",
    "\n",
    "}\n",
    "\n",
    "# Build proportional confusion matrix\n",
    "proportional_cm = pd.DataFrame(0, index=top_genres, columns=cluster_ids, dtype=float)\n",
    "for cluster_id in cluster_ids:\n",
    "    cluster_songs = df[df['kmeans_label'] == cluster_id]\n",
    "    genre_counts = cluster_songs['cleanGenre'].value_counts()\n",
    "    proportional_cm.loc[genre_counts.index.intersection(top_genres), cluster_id] = (\n",
    "        genre_counts.loc[genre_counts.index.intersection(top_genres)] / len(cluster_songs)\n",
    "    )\n",
    "\n",
    "# Convert to percentages + rename cluster columns with top genres\n",
    "percentage_cm = proportional_cm * 100\n",
    "percentage_cm.columns = [manual_labels [i] for i in cluster_ids]\n",
    "\n",
    "# Show as DataFrame\n",
    "print(\"Proportional Confusion Matrix (Top genres, in %):\")\n",
    "display(percentage_cm.round(2))\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "im = plt.imshow(percentage_cm, cmap=\"Greens\", aspect='auto')\n",
    "cbar = plt.colorbar(im); cbar.set_label(\"Percentage (%)\")\n",
    "plt.xticks(ticks=np.arange(len(percentage_cm.columns)), labels=percentage_cm.columns, rotation=45, ha=\"right\")\n",
    "plt.yticks(ticks=np.arange(len(percentage_cm.index)), labels=percentage_cm.index)\n",
    "plt.xlabel(\"Cluster Main Genre\"); plt.ylabel(\"True genres\"); plt.title(\"Proportional Confusion Matrix (%)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "323a486df540dfc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Task 3.1.4. Evaluate Inferred Labels** K-means",
   "id": "cd9b08685b1fd098"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "major_genres = [\n",
    "    \"synth-pop\", \"honky-tonk\", \"hard-rock\", \"psych-rock\", \"grunge\",\n",
    "    \"piano\", \"hard-rock, metal\", \"death-metal\", \"power-pop\", \"dance\"\n",
    "]\n",
    "# Keep only rows with major genres\n",
    "df_major = df[df['cleanGenre'].isin(major_genres)].copy()\n",
    "\n",
    "cluster_to_genre = {}\n",
    "for cluster_id in df_major['kmeans_label'].unique():\n",
    "    cluster_songs = df_major[df_major['kmeans_label'] == cluster_id]\n",
    "    majority_genre = cluster_songs['cleanGenre'].value_counts().idxmax()\n",
    "    cluster_to_genre[cluster_id] = majority_genre\n",
    "\n",
    "# Predicted labels\n",
    "y_pred = df_major['kmeans_label'].map(cluster_to_genre)\n",
    "y_true = df_major['cleanGenre']\n",
    "\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "print(classification_report(y_true, y_pred, zero_division=0))\n",
    "print(\"Macro Precision:\", precision_score(y_true, y_pred, average='macro', zero_division=0))\n",
    "print(\"Macro Recall:\", recall_score(y_true, y_pred, average='macro', zero_division=0))\n",
    "print(\"Macro F1:\", f1_score(y_true, y_pred, average='macro', zero_division=0))\n",
    "print(\"Weighted F1:\", f1_score(y_true, y_pred, average='weighted', zero_division=0))"
   ],
   "id": "5837ccd4ba3cb1ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Task 3.1.2. Apply Multiple Clustering Techniques** Hierarchical Method",
   "id": "111c0fb2831fd684"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#===================================================\n",
    "#hard boundaries in hierarchical methods { Agglomerative Clustering}\n",
    "#=====================================================\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "\n",
    "\n",
    "Z = linkage(X_tfidf, method='ward')\n",
    "\n",
    "plt.figure(figsize=(15, 9))\n",
    "dendrogram(Z)\n",
    "cut_height = 3.9\n",
    "plt.axhline(y=cut_height, c='red', lw=2, linestyle='--')\n",
    "plt.title(f'Dendrogram with cutoff at height={cut_height}')\n",
    "plt.show()\n",
    "\n",
    "clusters = fcluster(Z, t=cut_height, criterion='distance')\n",
    "df['hierarchical_cluster'] = clusters  # Add cluster labels\n",
    "\n",
    "#Step 4: Focus on a specific cluster\n",
    "cluster_number = 5\n",
    "cluster_mask = df['hierarchical_cluster'] == cluster_number\n",
    "Z_sub = linkage(X_tfidf[cluster_mask], method='ward')\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "dendrogram(Z_sub, leaf_rotation=90, leaf_font_size=10)\n",
    "plt.title(f\"Dendrogram for Cluster {cluster_number}\")\n",
    "plt.show()\n",
    "\n",
    "# --- Sorted subset table ---\n",
    "subset = df.loc[cluster_mask, ['song_id', 'name', 'cleanGenre']].copy()\n",
    "subset['DB_RowNo'] = np.arange(1, len(subset)+1)\n",
    "\n",
    "# Sort by genre frequency\n",
    "genre_order = subset['cleanGenre'].value_counts().index\n",
    "subset['cleanGenre'] = pd.Categorical(subset['cleanGenre'], categories=genre_order, ordered=True)\n",
    "subset_sorted = subset.sort_values('cleanGenre')[['DB_RowNo', 'name', 'cleanGenre']].reset_index(drop=True)\n",
    "\n",
    "#display(subset_sorted) optional for analysing the zoomed cluster\n"
   ],
   "id": "2900ee0ddd6136ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Task3.1.3. Visualise and Evaluate** Hierarchical Method",
   "id": "f0e87c0321f43475"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Assign hierarchical clusters\n",
    "df['cluster'] = clusters\n",
    "\n",
    "# Loop through each cluster\n",
    "for cluster_id in np.unique(clusters):\n",
    "    cluster_songs = df[df['cluster'] == cluster_id]\n",
    "    total_songs = len(cluster_songs)\n",
    "\n",
    "    # Count full genres as-is (even if multiple genres in one string)\n",
    "    genre_counts = cluster_songs['cleanGenre'].dropna().value_counts()\n",
    "\n",
    "    # Top 5 genres\n",
    "    top_genres = genre_counts.head(5)\n",
    "\n",
    "    # Build summary string\n",
    "    top_genre_summary = \", \".join([f\"{g} ({c}/{total_songs})\" for g, c in top_genres.items()])\n",
    "\n",
    "    # Print cluster header\n",
    "    print(f\"\\n=== Cluster {cluster_id} ({total_songs} songs) | Top genres: {top_genre_summary} ===\")\n",
    "\n",
    "    # Save cluster songs to CSV\n",
    "    output_folder = r\"MyFiles\"\n",
    "    filename = os.path.join(output_folder, f\"hard_cluster_{cluster_id}.csv\")\n",
    "    cluster_songs[['name', 'genre', 'cleanGenre', 'kmeans_label']].to_csv(filename, index=False)\n"
   ],
   "id": "72a2e003f541b4c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "# ===== Top 15 full genres =====\n",
    "top_15_genres = df['genre'].value_counts().head(15).index.tolist()\n",
    "cluster_ids = sorted(df['cluster'].unique())\n",
    "\n",
    "# ===== Manually assign a genre to each cluster =====\n",
    "# Example: cluster 0 -> 'rock', cluster 1 -> 'jazz', etc.\n",
    "manual_labels = {\n",
    "    1: 'grunge',\n",
    "    2: 'psych-rock ',\n",
    "    3: 'death-metal',\n",
    "    4: 'pop',\n",
    "    5: 'honky-tonk'\n",
    "}\n",
    "\n",
    "# ===== Initialize matrix =============\n",
    "proportional_cm = pd.DataFrame(0, index=top_15_genres, columns=cluster_ids, dtype=float)\n",
    "topic_labels = []\n",
    "\n",
    "# ===== Fill matrix & use manual labels =====\n",
    "for cluster_id in cluster_ids:\n",
    "    cluster_songs = df[df['cluster'] == cluster_id]\n",
    "    genre_counts = cluster_songs['cleanGenre'].dropna().value_counts()\n",
    "\n",
    "    # Use your manual label instead of top genre\n",
    "    top_genre_label = manual_labels.get(cluster_id, f\"Cluster {cluster_id}\")\n",
    "    topic_labels.append(top_genre_label)\n",
    "\n",
    "    for genre, count in genre_counts.items():\n",
    "        if genre in top_15_genres:\n",
    "            proportional_cm.loc[genre, cluster_id] = count / len(cluster_songs)\n",
    "\n",
    "\n",
    " # ===== Convert proportional matrix to percentages =====\n",
    "percentage_table = (percentage_cm).round(2)  # round to 2 decimal places\n",
    "\n",
    "# ===== Display table =====\n",
    "print(\"Proportional Confusion Matrix (Top genres, in %):\")\n",
    "display(percentage_table)\n",
    "\n",
    "# ===== Convert proportional matrix to percentages =====\n",
    "percentage_cm = proportional_cm * 100  # use proportional_cm with manual labels\n",
    "\n",
    "# ===== Replace numeric column IDs with manual labels =====\n",
    "percentage_cm.columns = [manual_labels.get(c, f\"Cluster {c}\") for c in percentage_cm.columns]\n",
    "\n",
    "# ===== Heatmap =====\n",
    "plt.figure(figsize=(10, 6))\n",
    "im = plt.imshow(percentage_cm.values, cmap=\"Greens\", aspect='auto')\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.set_label(\"Percentage (%)\")\n",
    "\n",
    "plt.xticks(ticks=np.arange(len(percentage_cm.columns)), labels=percentage_cm.columns, rotation=45, ha=\"right\")\n",
    "plt.yticks(ticks=np.arange(len(percentage_cm.index)), labels=percentage_cm.index)\n",
    "\n",
    "plt.xlabel(\"Cluster Main Genre\")\n",
    "plt.ylabel(\"True Genres\")\n",
    "plt.title(\"Proportional Confusion Matrix (%)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "e80746e71dbe9f7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**TASK 3.1.4. Evaluate Inferred Labels** Hierarchical Method",
   "id": "457f9f7de213812f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "top_15_genres = df['cleanGenre'].value_counts().head(15).index.tolist()\n",
    "\n",
    "# Keep only rows with these top genres\n",
    "df_major = df[df['cleanGenre'].isin(top_15_genres)].copy()\n",
    "\n",
    "cluster_to_genre = {}\n",
    "for cluster_id in df_major['kmeans_label'].unique():\n",
    "        cluster_songs = df_major[df_major['kmeans_label'] == cluster_id]\n",
    "        majority_genre = cluster_songs['cleanGenre'].value_counts().idxmax()\n",
    "        cluster_to_genre[cluster_id] = majority_genre\n",
    "\n",
    "y_pred = df_major['kmeans_label'].map(cluster_to_genre)\n",
    "y_true = df_major['cleanGenre']\n",
    "\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"Classification Report (Top 15 genres):\\n\")\n",
    "print(classification_report(y_true, y_pred, zero_division=0))\n",
    "\n",
    "print(\"Macro Precision:\", precision_score(y_true, y_pred, average='macro', zero_division=0))\n",
    "print(\"Macro Recall:\", recall_score(y_true, y_pred, average='macro', zero_division=0))\n",
    "print(\"Macro F1:\", f1_score(y_true, y_pred, average='macro', zero_division=0))\n",
    "print(\"Weighted F1:\", f1_score(y_true, y_pred, average='weighted', zero_division=0))\n"
   ],
   "id": "7e23e3e154c51ef4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**TASK 3.1.2. Apply Multiple Clustering Techniques** LDA Method",
   "id": "fe2895c85012d549"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Step 1: Convert text to Bag-of-Words\n",
    "count_vectorizer = CountVectorizer(max_features=55000)\n",
    "X_counts = count_vectorizer.fit_transform(df['clean_text'])\n",
    "\n",
    "# Step 2: Fit LDA\n",
    "n_topics = 5\n",
    "lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
    "lda.fit(X_counts)\n",
    "\n",
    "\n",
    "# LDA topic vectors\n",
    "topic_vectors = lda.transform(X_counts)\n",
    "df['assigned_topic'] = topic_vectors.argmax(axis=1)\n",
    "\n",
    "# Cluster in topic space\n",
    "k = 5\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "kmeans.fit(topic_vectors)\n",
    "df['kmeans_label'] = kmeans.labels_\n",
    "\n",
    "\n",
    "X_tsne = TSNE(n_components=2, random_state=42, perplexity=30).fit_transform(topic_vectors)\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=df['kmeans_label'], cmap='tab10', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# Print songs per topic\n",
    "for topic_id in sorted(df['assigned_topic'].unique()):\n",
    "    topic_songs = df[df['assigned_topic'] == topic_id]\n",
    "    total_songs = len(topic_songs)\n",
    "\n",
    "    # Split all genre strings by comma and flatten\n",
    "    all_subgenres = topic_songs['cleanGenre'].dropna().apply(lambda x: [g.strip() for g in x.split(',')])\n",
    "    all_subgenres_flat = [g for sublist in all_subgenres for g in sublist]\n",
    "\n",
    "    # Count each subgenre\n",
    "    from collections import Counter\n",
    "    subgenre_counts = Counter(all_subgenres_flat)\n",
    "\n",
    "    # Take top 5\n",
    "    top5_subgenres = subgenre_counts.most_common(5)\n",
    "    top5_str = \", \".join([f\"{g} ({c})\" for g, c in top5_subgenres])\n",
    "\n",
    "    print(f\"\\n=== Topic {topic_id} ({total_songs} songs) | Top subgenres: {top5_str} ===\")\n",
    "    #print(topic_songs[['name', 'cleanGenre', 'assigned_topic']].to_string(index=False))\n",
    "\n"
   ],
   "id": "41caab8aa5eab9d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Task 3.1.3. Visualise and Evaluate** LDA Method",
   "id": "ad3071fc55a22e4f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ===== Top genres =====\n",
    "top_10_genres = df['genre'].value_counts().head(15).index.tolist()\n",
    "\n",
    "# ===== LDA topics =====\n",
    "topic_ids = sorted(df['assigned_topic'].unique())\n",
    "\n",
    "# ===== Manually assign labels to topics =====\n",
    "manual_labels = {\n",
    "    0: \"hard-rock\",\n",
    "    1: \"grunge\",\n",
    "    2: \"death-metal\",\n",
    "    3: \"psych-rock\",\n",
    "    4: \"honky-tonk\",\n",
    "\n",
    "}\n",
    "\n",
    "# Initialize proportional matrix\n",
    "proportional_cm = pd.DataFrame(0, index=top_10_genres, columns=topic_ids, dtype=float)\n",
    "\n",
    "# Fill matrix\n",
    "for topic_id in topic_ids:\n",
    "    topic_songs = df[df['assigned_topic'] == topic_id]\n",
    "    genre_counts = topic_songs['cleanGenre'].value_counts()\n",
    "    for genre, count in genre_counts.items():\n",
    "        if genre in top_10_genres:\n",
    "            proportional_cm.loc[genre, topic_id] = count / len(topic_songs) if len(topic_songs) > 0 else 0\n",
    "\n",
    "# ===== Replace numeric topic IDs with manual labels =====\n",
    "proportional_cm.columns = [manual_labels.get(tid, f\"Topic {tid}\") for tid in proportional_cm.columns]\n",
    "\n",
    "# Convert to percentages\n",
    "percentage_cm = proportional_cm * 100\n",
    "percentage_table = percentage_cm.round(2).astype(str) + \"%\"\n",
    "\n",
    "print(\"Proportional Confusion Matrix (Top genres, in %):\")\n",
    "print(percentage_table)\n",
    "\n",
    "# ===== Plot heatmap =====\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(proportional_cm, cmap=\"Greens\", aspect='auto')\n",
    "plt.colorbar(label=\"Proportion\")\n",
    "plt.xticks(ticks=np.arange(len(proportional_cm.columns)), labels=proportional_cm.columns, rotation=45, ha='right')\n",
    "plt.yticks(ticks=np.arange(len(proportional_cm.index)), labels=proportional_cm.index)\n",
    "plt.xlabel(\"LDA Topics (Manual Labels)\")\n",
    "plt.ylabel(\"True Genres\")\n",
    "plt.title(\"Proportional Confusion Matrix (LDA)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "f34689d3ec7728d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Task3.1.4. Evaluate Inferred Labels** LDA Method",
   "id": "7c20f1acec3d4ea4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "major_genres = [\n",
    "    \"synth-pop\", \"honky-tonk\", \"hard-rock\", \"psych-rock\", \"grunge\",\n",
    "    \"piano\", \"hard-rock, metal\", \"death-metal\", \"power-pop\", \"dance\"\n",
    "]\n",
    "df_major = df[df['cleanGenre'].isin(major_genres)].copy()\n",
    "\n",
    "# Map each LDA topic to its majority genre\n",
    "topic_to_genre = {}\n",
    "for topic_id in df_major['assigned_topic'].unique():\n",
    "    topic_songs = df_major[df_major['assigned_topic'] == topic_id]\n",
    "    majority_genre = topic_songs['cleanGenre'].value_counts().idxmax()\n",
    "    topic_to_genre[topic_id] = majority_genre\n",
    "\n",
    "# Predicted labels\n",
    "y_pred = df_major['assigned_topic'].map(topic_to_genre)\n",
    "y_true = df_major['cleanGenre']\n",
    "\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_true, y_pred, zero_division=0))\n",
    "\n",
    "# Macro / weighted metrics\n",
    "print(\"Macro Precision:\", precision_score(y_true, y_pred, average='macro', zero_division=0))\n",
    "print(\"Macro Recall:\", recall_score(y_true, y_pred, average='macro', zero_division=0))\n",
    "print(\"Macro F1:\", f1_score(y_true, y_pred, average='macro', zero_division=0))\n",
    "print(\"Weighted F1:\", f1_score(y_true, y_pred, average='weighted', zero_division=0))\n"
   ],
   "id": "7925b0476ec9377e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " **Final Thoughts**\n",
    "\n",
    "I tried my best to keep the pre-clustering preprocessing as light as possible. In fact, I even had to remove lemmatization, because including it actually made the clustering results worse.<br>I also attempted to clean the genre field, since many songs had duplicate or multiple genre labels. In those cases, I experimented with strategies like picking the rarest genre to make clustering more interesting.\n",
    "\n",
    "I experimented with three clustering methods:<br>\n",
    "-KMeans<br>\n",
    "-Hierarchical clustering<br>\n",
    "-Latent Dirichlet Allocation (LDA)<br>\n",
    "<br>\n",
    "Across all three, performance was consistently poor. The metrics back this up:\n",
    "-Macro Precision: ~0.07 – 0.10<br>\n",
    "-Macro Recall: ~0.11 – 0.19<br>\n",
    "-Macro F1: ~0.04 – 0.09<br>\n",
    "-Weighted F1: ~0.06 – 0.13<br>\n",
    "<br>\n",
    "When analyzing the clusters, it became clear that each one was essentially a soup of mixed genres rather than clean, separable groups. This was expected given the dataset: the database is heavily biased toward Rock, Grunge, and Honky-Tonk, so naturally most clusters ended up being dominated by those genres.\n",
    "\n",
    "Another challenge was that, across methods, some clusters were repeatedly dominated by the same genres. For example:<br>Cluster 1 (768 songs) → Grunge<br>Cluster 2 (204 songs) → Psych-Rock<br>Cluster 3 (354 songs) → Death-Metal<br>Cluster 4 (104 songs) → Honky-Tonk<br>Cluster 5 (128 songs) → Honky-Tonk<br>Since Grunge, Hard Rock, and Honky-Tonk kept surfacing in multiple clusters, I had to manually rename the repeated clusters and assign them into the proportional confusion matrix, ensuring that each cluster represented a distinct dominant genre.\n",
    "\n",
    "Another key decision was to opt out of the standard confusion matrix. Instead, I used a proportional confusion matrix. This choice allowed me to capture the mixture of genres and show how they tended to distribute across clusters, rather than forcing misleading hard labels."
   ],
   "id": "5c77d45d2ab73c87"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
