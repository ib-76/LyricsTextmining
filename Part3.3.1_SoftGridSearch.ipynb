{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " **Task 3.3: Parameter Tuning Using Grid Search**<br>The grid search explored **8 parameters** across three pipeline stages:\n",
    "\n",
    "- **TF–IDF Vectorization**\n",
    "  - `max_features`\n",
    "  - `ngram_range`\n",
    "  - `min_df`\n",
    "- **SVD (Latent Semantic Analysis)**\n",
    "  - `n_components`\n",
    "  - `svd_random_state`\n",
    "- **KMeans Clustering**\n",
    "  - `n_clusters`\n",
    "  - `kmeans_n_init`\n",
    "  - `kmeans_random_state`\n"
   ],
   "id": "74a17b1e209b9d46"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.special import softmax\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "\n",
    "def full_clustering_pipeline(connection_string,\n",
    "                             table_name='songs',\n",
    "                             text_column='cleanTokens',\n",
    "                             # TF-IDF params\n",
    "                             max_features=9000,\n",
    "                             ngram_range=(1, 2),\n",
    "                             min_df=25,\n",
    "                             max_df=0.9,\n",
    "                             # SVD params\n",
    "                             n_components=120,\n",
    "                             svd_random_state=100,\n",
    "                             # KMeans params\n",
    "                             n_clusters=6,\n",
    "                             kmeans_n_init=250,\n",
    "                             kmeans_random_state=100,\n",
    "                             # options\n",
    "                             soft_assign=True,\n",
    "                             distance_metric='euclidean',\n",
    "                             visualize=True,\n",
    "                             table_show=False,\n",
    "                             save_excel=False):\n",
    "    \"\"\"\n",
    "    Full pipeline: load SimilarityData, TF-IDF, SVD, KMeans clustering, soft assignment, PCA visualization.\n",
    "    Returns: df, X_reduced, prob_df, silhouette_score, vectorizer, svd, kmeans\n",
    "    \"\"\"\n",
    "    # =====  Load & preprocess =====\n",
    "    engine = create_engine(connection_string)\n",
    "    df = pd.read_sql(f\"\"\"\n",
    "        SELECT song_id, name, {text_column}, cleanGenre\n",
    "        FROM {table_name}\n",
    "        WHERE {text_column} IS NOT NULL\n",
    "    \"\"\", engine)\n",
    "\n",
    "    df[text_column] = df[text_column].apply(ast.literal_eval)\n",
    "    df['clean_text'] = df[text_column].apply(lambda tokens: ' '.join(map(str, tokens)))\n",
    "\n",
    "    # =====  TF-IDF =====\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_features=max_features,\n",
    "        ngram_range=ngram_range,\n",
    "        min_df=min_df,\n",
    "        max_df=max_df,\n",
    "        lowercase=True,\n",
    "        strip_accents='unicode',\n",
    "        token_pattern=r'\\b\\w+\\b'\n",
    "    )\n",
    "    X_sparse = vectorizer.fit_transform(df['clean_text'])\n",
    "\n",
    "    # =====  Truncated SVD (LSA) =====\n",
    "    svd = TruncatedSVD(n_components=min(n_components, X_sparse.shape[1]),\n",
    "                       random_state=svd_random_state)\n",
    "    X_reduced = svd.fit_transform(X_sparse)\n",
    "\n",
    "    # ===== 4 KMeans clustering =====\n",
    "    kmeans = KMeans(n_clusters=n_clusters,\n",
    "                    n_init=kmeans_n_init,\n",
    "                    random_state=kmeans_random_state)\n",
    "    kmeans.fit(X_reduced)\n",
    "\n",
    "    df['kmeans_label'] = kmeans.labels_\n",
    "    sil_score = silhouette_score(X_reduced, kmeans.labels_)\n",
    "\n",
    "    # =====  Soft assignments =====\n",
    "    prob_df = None\n",
    "    assigned_cluster = kmeans.labels_\n",
    "    if soft_assign:\n",
    "        centroids = kmeans.cluster_centers_\n",
    "        dists = cdist(X_reduced, centroids, metric=distance_metric)\n",
    "        probabilities = softmax(-dists, axis=1)\n",
    "        assigned_cluster = probabilities.argmax(axis=1)\n",
    "        prob_df = pd.DataFrame(probabilities,\n",
    "                               columns=[f'Cluster_{i + 1}' for i in range(n_clusters)],\n",
    "                               index=df.index)\n",
    "        prob_df['assigned_cluster'] = assigned_cluster\n",
    "\n",
    "    # =====  Visualization =====\n",
    "    if visualize:\n",
    "        pca = PCA(n_components=2)\n",
    "        X_pca = pca.fit_transform(X_reduced)\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1],\n",
    "                              c=assigned_cluster,\n",
    "                              cmap='tab10', alpha=0.8, s=40)\n",
    "        plt.xlabel('PCA Component 1')\n",
    "        plt.ylabel('PCA Component 2')\n",
    "        plt.title(f'KMeans Clusters (k={n_clusters}) in 2D PCA')\n",
    "        plt.legend(*scatter.legend_elements(), title=\"Clusters\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # ===== 7️⃣ Top subgenres per cluster & Excel =====\n",
    "    if table_show or save_excel:\n",
    "        for cluster_id in sorted(df['kmeans_label'].unique()):\n",
    "            cluster_songs = df[df['kmeans_label'] == cluster_id]\n",
    "            total_songs = len(cluster_songs)\n",
    "            all_subgenres = cluster_songs['cleanGenre'].dropna().apply(lambda x: [g.strip() for g in x.split(',')])\n",
    "            all_subgenres_flat = [g for sublist in all_subgenres for g in sublist]\n",
    "            subgenre_counts = Counter(all_subgenres_flat)\n",
    "            top5_subgenres = subgenre_counts.most_common(5)\n",
    "            top5_summary = \", \".join([f\"{g} ({c}/{total_songs})\" for g, c in top5_subgenres])\n",
    "            print(f\"\\n=== Cluster {cluster_id} ({total_songs} songs) | Top subgenres: {top5_summary} ===\")\n",
    "\n",
    "            if save_excel:\n",
    "                filename = f\"cluster_{cluster_id}.xlsx\"\n",
    "                cluster_songs[['name', 'cleanGenre', 'kmeans_label']].to_excel(filename, index=False)\n",
    "\n",
    "    return df, X_reduced, prob_df, sil_score, vectorizer, svd, kmeans\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def clustering_grid_search(connection_string,\n",
    "                           max_features_list=[9000],\n",
    "                           ngram_range_list=[(1, 2)],\n",
    "                           min_df_list=[25],\n",
    "                           n_components_list=[120],\n",
    "                           svd_random_state_list=[100],\n",
    "                           n_clusters_list=[6],\n",
    "                           kmeans_n_init_list=[250],\n",
    "                           kmeans_random_state_list=[100],\n",
    "                           verbose=True):\n",
    "    \"\"\"\n",
    "    Perform a grid search over TF-IDF, SVD, and KMeans params.\n",
    "    Returns a pandas DataFrame sorted by silhouette score.\n",
    "    Grid-searches 8 features: max_features, ngram_range, min_df,\n",
    "    n_components, svd_random_state, n_clusters, kmeans_n_init,\n",
    "    kmeans_random_state.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for max_features, ngram_range, min_df, n_components, svd_rs, n_clusters, kmeans_init, kmeans_rs in itertools.product(\n",
    "        max_features_list, ngram_range_list, min_df_list,\n",
    "        n_components_list, svd_random_state_list,\n",
    "        n_clusters_list, kmeans_n_init_list, kmeans_random_state_list):\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Testing: max_features={max_features}, ngram_range={ngram_range}, \"\n",
    "                  f\"min_df={min_df}, n_components={n_components}, svd_random_state={svd_rs}, \"\n",
    "                  f\"n_clusters={n_clusters}, kmeans_n_init={kmeans_init}, kmeans_random_state={kmeans_rs}\")\n",
    "\n",
    "        try:\n",
    "            _, _, _, sil_score, _, _, _ = full_clustering_pipeline(\n",
    "                connection_string=connection_string,\n",
    "                max_features=max_features,\n",
    "                ngram_range=ngram_range,\n",
    "                min_df=min_df,\n",
    "                n_components=n_components,\n",
    "                svd_random_state=svd_rs,\n",
    "                n_clusters=n_clusters,\n",
    "                kmeans_n_init=kmeans_init,\n",
    "                kmeans_random_state=kmeans_rs,\n",
    "                soft_assign=False,\n",
    "                visualize=False,\n",
    "                table_show=False,\n",
    "                save_excel=False\n",
    "            )\n",
    "            results.append({\n",
    "                'max_features': max_features,\n",
    "                'ngram_range': ngram_range,\n",
    "                'min_df': min_df,\n",
    "                'n_components': n_components,\n",
    "                'svd_random_state': svd_rs,\n",
    "                'n_clusters': n_clusters,\n",
    "                'kmeans_n_init': kmeans_init,\n",
    "                'kmeans_random_state': kmeans_rs,\n",
    "                'silhouette_score': sil_score\n",
    "            })\n",
    "            if verbose:\n",
    "                print(f\"→ Silhouette score: {sil_score:.4f}\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"Skipped combination due to error: {e}\")\n",
    "\n",
    "    results_df = pd.DataFrame(results).sort_values(by='silhouette_score', ascending=False).reset_index(drop=True)\n",
    "    return results_df\n",
    "\n"
   ],
   "id": "9efdce7317a41b66",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "conn_str = \"mssql+pyodbc://IVAN_PC\\\\SQLEXPRESS/TextMiningHA?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "\n",
    "grid_results = clustering_grid_search(\n",
    "    connection_string=conn_str,\n",
    "    max_features_list=[8000,10000],\n",
    "    ngram_range_list=[(1,1),(1, 2)],\n",
    "    min_df_list=[90,100],\n",
    "    n_components_list=     [35,40,50],\n",
    "    svd_random_state_list=[ 40,50],\n",
    "    n_clusters_list=[5,6,7],\n",
    "    kmeans_n_init_list=[50,100],\n",
    "    kmeans_random_state_list=[ 80,90, 100]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "display(grid_results)"
   ],
   "id": "fd9fed5a2917d188",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Best Combination Found\n",
    "| max_features | ngram_range | min_df | n_components | svd_random_state | n_clusters | kmeans_n_init | kmeans_random_state | silhouette_score |\n",
    "|--------------|-------------|--------|---------------|------------------|------------|----------------|---------------------|------------------|\n",
    "| 10000        | (1, 2)      | 100    | 40            | 40               | 5          | 50             | 90                  | 0.084666         |\n",
    "\n",
    "\n",
    "Conclusion: the pipeline runs successfully and systematically explores 8 parameters, but the data itself still not lend well to clean KMeans partitions under TF–IDF + SVD.\n",
    "\n"
   ],
   "id": "246b83c18448dc48"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
